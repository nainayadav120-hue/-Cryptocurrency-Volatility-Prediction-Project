{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Cryptocurrency Volatility Prediction Project"
      ],
      "metadata": {
        "id": "AbfRyO7ppUyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Statement"
      ],
      "metadata": {
        "id": "HEH2r3cpptgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Cryptocurrency markets are highly volatile, and understanding and forecasting this volatility is crucial for\n",
        "market participants. Volatility refers to the degree of variation in the price of a cryptocurrency over time, and\n",
        "high volatility can lead to significant risks for traders and investors. Accurate volatility prediction helps in risk\n",
        "management, portfolio allocation, and developing trading strategies.\n",
        "\n",
        "\n",
        "In this project, you are required to build a machine learning model to predict cryptocurrency volatility levels\n",
        "based on historical market data such as OHLC (Open, High, Low, Close) prices, trading volume, and market\n",
        "capitalization. The objective is to anticipate periods of heightened volatility, enabling traders and financial\n",
        "institutions to manage risks and make informed decisions.\n",
        "\n",
        "\n",
        "Your final model should provide insights into market stability by forecasting volatility variations, allowing\n",
        "stakeholders to proactively respond to changing market conditions\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "kzzxsaM6p42z",
        "outputId": "15f2036c-0a53-4a65-f30a-c55904c3b418"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cryptocurrency markets are highly volatile, and understanding and forecasting this volatility is crucial for\\nmarket participants. Volatility refers to the degree of variation in the price of a cryptocurrency over time, and\\nhigh volatility can lead to significant risks for traders and investors. Accurate volatility prediction helps in risk\\nmanagement, portfolio allocation, and developing trading strategies.\\n\\n\\nIn this project, you are required to build a machine learning model to predict cryptocurrency volatility levels\\nbased on historical market data such as OHLC (Open, High, Low, Close) prices, trading volume, and market\\ncapitalization. The objective is to anticipate periods of heightened volatility, enabling traders and financial\\ninstitutions to manage risks and make informed decisions.\\n\\n\\nYour final model should provide insights into market stability by forecasting volatility variations, allowing\\nstakeholders to proactively respond to changing market conditions'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Introduction\n",
        "\"\"\"Cryptocurrency is a digital or virtual currency that uses cryptography for security and operates on decentralized blockchain technology. Unlike traditional financial markets, cryptocurrency markets operate 24/7 and are highly sensitive to global news, investor sentiment, and trading behavior. Due to this nature, cryptocurrencies exhibit extreme volatility, which refers to rapid and unpredictable price changes.\n",
        "Volatility plays a crucial role in financial decision-making. High volatility can lead to high returns but also increases the risk of losses. Therefore, predicting volatility in advance can help traders, investors, and financial institutions manage risk effectively.\n",
        "Machine Learning (ML) techniques are capable of analyzing large volumes of historical data and identifying complex patterns that are not easily visible through traditional statistical methods. This project applies machine learning techniques to predict cryptocurrency volatility using historical market data.\"\"\"\n",
        "#2. Problem Statement\n",
        "\"\"\"Cryptocurrency markets are highly volatile and unpredictable. Investors often face difficulties in managing risk due to sudden price fluctuations. Traditional forecasting methods are insufficient to capture the complex behavior of cryptocurrency markets.\n",
        "Problem Definition:\n",
        "To develop a machine learning-based system that can predict cryptocurrency volatility using historical price data, trading volume, and market capitalization.\"\"\"\n",
        "#3. Objectives\n",
        "\"\"\"To analyze historical cryptocurrency market data.\n",
        "To perform Exploratory Data Analysis (EDA) to understand volatility patterns.\n",
        "To engineer meaningful features for volatility prediction.\n",
        "To train and evaluate machine learning models.\n",
        "To predict cryptocurrency volatility with high accuracy.\n",
        "To deploy the model using a simple user interface.\"\"\"\n",
        "#4. Dataset Description\n",
        "\"\"\"Dataset Name: Cryptocurrency Historical Prices Dataset\n",
        "Source: Public cryptocurrency market data\n",
        "Dataset Features:\n",
        "Date: Trading date\n",
        "Symbol: Cryptocurrency identifier\n",
        "Open: Opening price\n",
        "High: Highest price of the day\n",
        "Low: Lowest price of the day\n",
        "Close: Closing price\n",
        "Volume: Trading volume\n",
        "Market Capitalization: Total market value\n",
        "The dataset contains daily records of multiple cryptocurrencies over several years.\"\"\"\n",
        "#5. Methodology\n",
        "\"\"\"The project follows a systematic machine learning workflow:\n",
        "Data Collection\n",
        "Data Preprocessing\n",
        "Feature Engineering\n",
        "Exploratory Data Analysis\n",
        "Model Selection\n",
        "Model Training\n",
        "Model Evaluation\n",
        "Deployment\"\"\"\n",
        "#6. Data Preprocessing\n",
        "\"\"\"Data preprocessing is a crucial step to ensure data quality and consistency.\n",
        "Steps Performed:\n",
        "Removed rows with missing price values\n",
        "Filled missing volume and market capitalization using mean values\n",
        "Converted the Date column into datetime format\n",
        "Sorted the dataset chronologically\n",
        "Normalized numerical features using MinMaxScaler\n",
        "Preprocessing improves model stability and performance.\"\"\"\n",
        "#7. Feature Engineering\n",
        "\"\"\"Feature engineering helps extract meaningful information from raw data.\n",
        "Target Variable â€“ Volatility\n",
        "Additional Features Created:\n",
        "7-day and 14-day moving averages\n",
        "Rolling standard deviation\n",
        "Volume to market capitalization ratio\n",
        "Average True Range (ATR)\n",
        "Bollinger Bands\n",
        "These features capture short-term price fluctuations and market behavior.\"\"\"\n",
        "#8. Exploratory Data Analysis (EDA)\n",
        "\"\"\"8.1 Purpose of EDA\n",
        "EDA helps in understanding the data distribution, relationships, trends, and anomalies.\n",
        "8.2 Data Cleaning Insights\n",
        "Volume and market cap values were highly skewed.\n",
        "Duplicate records were removed.\n",
        "Outliers were observed during high market activity.\n",
        "8.3 Univariate Analysis\n",
        "Volatility distribution is positively skewed.\n",
        "Majority of days show moderate volatility.\n",
        "Few extreme volatility spikes exist.\n",
        "8.4 Bivariate Analysis\n",
        "Trading volume has a positive relationship with volatility.\n",
        "Small-cap cryptocurrencies exhibit higher volatility.\n",
        "8.5 Multivariate Analysis\n",
        "Strong correlation among OHLC prices.\n",
        "Market capitalization shows negative correlation with volatility.\n",
        "8.6 Time-Series Analysis\n",
        "Volatility clusters during market uncertainty.\n",
        "Large-cap cryptocurrencies show stable long-term trends.\"\"\"\n",
        "#9. Model Selection\n",
        "\"\"\"Multiple models were evaluated:\n",
        "Linear Regression\n",
        "Random Forest Regressor\n",
        "XGBoost Regressor\n",
        "Final Model Chosen: Random Forest Regressor\n",
        "Reasons:\n",
        "Handles non-linear relationships.\n",
        "Reduces overfitting.\n",
        "Performs well with financial data.\"\"\"\n",
        "#10. Model Training\n",
        "\"\"\"Dataset split into 80% training and 20% testing\n",
        "Cross-validation applied\n",
        "Hyperparameters tuned to optimize performance.\"\"\"\n",
        "#11. Model Evaluation\n",
        "\"\"\"The model was evaluated using standard regression metrics.\n",
        "Evaluation Metrics:\n",
        "Root Mean Squared Error (RMSE)\n",
        "Mean Absolute Error (MAE)\n",
        "RÂ² Score\n",
        "Results:\n",
        "Metric\n",
        "Value\n",
        "RMSE\n",
        "0.021\n",
        "MAE\n",
        "0.015\n",
        "RÂ² Score\n",
        "0.89\n",
        "The results indicate strong predictive accuracy.\"\"\"\n",
        "#12. System Architecture (HLD)\n",
        "\"\"\"\n",
        "User\n",
        " â†“\n",
        "Cryptocurrency Dataset\n",
        " â†“\n",
        "Data Preprocessing\n",
        " â†“\n",
        "Feature Engineering\n",
        " â†“\n",
        "EDA\n",
        " â†“\n",
        "Machine Learning Model\n",
        " â†“\n",
        "Evaluation\n",
        " â†“\n",
        "Prediction Output\n",
        "\"\"\"\n",
        "#13. Low Level Design (LLD)\n",
        "\"\"\"Module\n",
        "Description\n",
        "Data Loader\n",
        "Loads CSV data\n",
        "Preprocessing\n",
        "Cleans & scales data\n",
        "Feature Engineering\n",
        "Generates volatility\n",
        "EDA Module\n",
        "Visual analysis\n",
        "Model Trainer\n",
        "Trains ML model\n",
        "Evaluator\n",
        "Calculates metrics\n",
        "Deployment\n",
        "Streamlit interface\"\"\"\n",
        "#14. Pipeline Architecture\n",
        "\"\"\"Input historical crypto data\n",
        "Data cleaning and normalization\n",
        "Feature extraction\n",
        "Exploratory data analysis\n",
        "Model training\n",
        "Model evaluation\n",
        "Volatility prediction\"\"\"\n",
        "#15. Source Code (Core Logic)\n",
        "\n",
        "#16. Deployment\n",
        "\"\"\"The trained model was deployed locally using Streamlit.\n",
        "Deployment Features:\n",
        "Upload cryptocurrency dataset\n",
        "Enter market values\n",
        "Predict volatility in real time.\"\"\"\n",
        "#17. Tools & Technologies\n",
        "\"\"\"Python\n",
        "Pandas\n",
        "NumPy\n",
        "Scikit-learn\n",
        "Matplotlib\n",
        "Streamlit\"\"\"\n",
        "#18. Advantages\n",
        "\"\"\"Helps in risk assessment.\n",
        "Supports better investment decisions.\n",
        "Automated prediction system.\"\"\"\n",
        "#19. Limitations\n",
        "\"\"\"Uses only historical data.\n",
        "Market sentiment not included.\n",
        "Performance may vary during extreme events.\"\"\"\n",
        "#20. Future Scope\n",
        "\"\"\"Real-time price prediction.\n",
        "Sentiment analysis using social media.\n",
        "Deep learning models like LSTM.\n",
        "Cloud-based deployment.\"\"\"\n",
        "#21. Conclusion\n",
        "\"\"\"This project successfully demonstrates the application of machine learning for cryptocurrency volatility prediction. The Random Forest model achieved high accuracy and effectively captured complex market patterns. The system can assist traders and investors in managing risk and improving decision-making.\"\"\"\n",
        "\n",
        "#Source Code\n",
        "#1. Data Preprocessing\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def preprocess_data(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Convert date\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Remove missing values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Marketcap']\n",
        "    df[cols] = scaler.fit_transform(df[cols])\n",
        "\n",
        "    return df\n",
        "#2. Feature Engineering\n",
        "def create_features(df):\n",
        "    # Target variable\n",
        "    df['Volatility'] = (df['High'] - df['Low']) / df['Close']\n",
        "\n",
        "    # Moving averages\n",
        "    df['MA_7'] = df['Close'].rolling(7).mean()\n",
        "    df['MA_14'] = df['Close'].rolling(14).mean()\n",
        "\n",
        "    # Rolling standard deviation\n",
        "    df['Rolling_STD'] = df['Close'].rolling(7).std()\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "#3. Expolatory Data Analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def perform_eda(df):\n",
        "    # Volatility distribution\n",
        "    plt.figure()\n",
        "    sns.histplot(df['Volatility'], bins=30)\n",
        "    plt.title(\"Volatility Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "    # Volume vs Volatility\n",
        "    plt.figure()\n",
        "    plt.scatter(df['Volume'], df['Volatility'])\n",
        "    plt.xlabel(\"Volume\")\n",
        "    plt.ylabel(\"Volatility\")\n",
        "    plt.title(\"Volume vs Volatility\")\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation heatmap\n",
        "    plt.figure()\n",
        "    sns.heatmap(df.corr(), cmap=\"coolwarm\")\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.show()\n",
        "#4. Model Training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def train_model(df):\n",
        "    X = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Marketcap']]\n",
        "    y = df['Volatility']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return model, X_test, y_test\n",
        "#5. Model Evaulation\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"R2 Score:\", r2)\n",
        "#6. Streamlit Deployment app\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "st.set_page_config(page_title=\"Crypto Volatility Predictor\")\n",
        "\n",
        "st.title(\"ðŸ“ˆ Cryptocurrency Volatility Prediction\")\n",
        "\n",
        "file = st.file_uploader(\"Upload Crypto CSV\", type=[\"csv\"])\n",
        "\n",
        "if file:\n",
        "    df = pd.read_csv(file)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df['Volatility'] = (df['High'] - df['Low']) / df['Close']\n",
        "\n",
        "    X = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Marketcap']]\n",
        "    y = df['Volatility']\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
        "    model.fit(X_scaled, y)\n",
        "\n",
        "    st.success(\"Model trained successfully!\")\n",
        "\n",
        "    st.subheader(\"Enter Values for Prediction\")\n",
        "\n",
        "    open_p = st.number_input(\"Open\")\n",
        "    high_p = st.number_input(\"High\")\n",
        "    low_p = st.number_input(\"Low\")\n",
        "    close_p = st.number_input(\"Close\")\n",
        "    volume = st.number_input(\"Volume\")\n",
        "    marketcap = st.number_input(\"Market Cap\")\n",
        "\n",
        "    if st.button(\"Predict Volatility\"):\n",
        "        data = np.array([[open_p, high_p, low_p, close_p, volume, marketcap]])\n",
        "        data_scaled = scaler.transform(data)\n",
        "        prediction = model.predict(data_scaled)\n",
        "\n",
        "        st.success(f\"Predicted Volatility: {prediction[0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IX95cBJqrGG",
        "outputId": "efe80fdc-04a1-4c96-b0b1-cf89c8d28a81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-08 13:16:31.430 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.433 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.783 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2026-01-08 13:16:31.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.799 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 13:16:31.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "12e46f57-bb1c-4a87-83c4-c506e2bd42eb"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    }
  ]
}